{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Exam Take Home (Part 1) - fMRI analysis\n",
    "\n",
    "#### **All files needed for the final are contained within the folder final**\n",
    "\n",
    "### The Final Exam is divided into 2 parts.  The first part involves using Linear Discriminant Analysis (LDA) to analyze fMRI data related to working memory using a comparison of a **n-back (n=2)** task with **target detection**, using different types of visual stimuli known to activate different parts of the brain. In an n-back task, subjects are presented a sequence of stimuli. The task is to detect whether the stimuli are repeats with a separation of n items.  This task is popular in studies of working memory because the subject has to hold the last n stimuli in sequence in memory, and the load on working memory can be parametrically varied by increasing n. \n",
    "\n",
    "### The task here was designed to separately manipulate aspects of working memory.  First, the two tasks contrast the engagement of areas of the brain involved in working memory computations in the brain.  Second, the use of different types of visual stimuli involves different parts of the brain that process the stimuli and potentially hold separately the representation of the stimulus in working memory.  \n",
    "\n",
    "### The data for this task is in the file 'WM_fmri_subjectaverage.mat'.  The data has been averaged over fmri scans in each of 100 participants for each experimental condition. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README \n",
    "\n",
    "### After you load the data (import loadmat from hdf5storage), you will get a dictionary with the following keys.  \n",
    "\n",
    "#### condition_index - index for each data sample, indicating the experimental condition \n",
    "#### conditions - conditions in the experiment \n",
    "#### fmri - fmri data averaged over participants, nregions x (nsubjects x nconditions)\n",
    "#### nconditions - number of conditions (in this case, 8)\n",
    "#### nregions - number of regions (always 360)\n",
    "#### nsubjects - number of subjects (always 100)\n",
    "#### subject - indexes which subject each average comes from. \n",
    "#### task - which task the data comes from.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the Working Memory data set, each condition is labeled in 2 ways.  \n",
    "#### First the task is either\n",
    "* #### '0bk' - target detection (condition_index 0-3) \n",
    "* #### '2bk' - working memory task (condition_index 4-7)\n",
    "#### The stimulus category is one of \n",
    "* #### 'body' - body parts (condition_index = 0/4) \n",
    "* #### 'faces' - human faces (condition_index = 1/5)\n",
    "* #### 'places' - landscapes (condition_index = 2/6) \n",
    "* #### 'tools' - common tools (condition_index = 3/7)\n",
    "#### The 8 conditions reflect a combination of task and category labeled by condition_index 0 to 7 \n",
    "* #### 0: '0bk_body'\n",
    "* #### 1: '0bk_faces'\n",
    "* #### 2: '0bk_places'\n",
    "* #### 3: '0bk_tools'\n",
    "* #### 4: '2bk_body'\n",
    "* #### 5: '2bk_faces'\n",
    "* #### 6: '2bk_places'\n",
    "* #### 7: '2bk_tools'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your task is to analyze this data using LDA to answer questions about working memory and brain networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Analyze the effect of engaging working memory in fMRI data by computing the difference in the fMRI response in the '0bk' (target detection) and '2bk' (working memory) conditions.  Identify the ROIs that show the strongest difference (Hint: Don't forget to z-score the data, so your difference reflect standardized effect sizes), by ranking the ROIs by effect size, and making a table of the top 10 ROI that show the largest magnitude difference.  The table should show the ROI name, the network they belong to, and the value of the standardized difference (including sign).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_VMV2 Visual2 0.822591430251323\n",
      "L_a9-46v Frontopariet -0.8310277359080279\n",
      "R_s6-8 Frontopariet -0.8759659667624611\n",
      "L_p9-46v Frontopariet -0.8929985660844207\n",
      "L_IP2 Frontopariet -0.9083078738868102\n",
      "R_IP2 Frontopariet -0.9106476992693794\n",
      "L_i6-8 Frontopariet -0.9828658626497757\n",
      "L_7Pm Frontopariet -0.9955017122085765\n",
      "R_i6-8 Frontopariet -1.0091968064651822\n",
      "R_7Pm Frontopariet -1.121760713741677\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt \n",
    "from hdf5storage import loadmat, savemat \n",
    "hcppath = '/Applications/neuralanalytics/fmrihcp_task/'#'/home/ramesh/Teaching/classdata/fmri/hcp_task/'\n",
    "datapath = hcppath+'processed/'\n",
    "regions = np.load('regions.npy') # this is the file \n",
    "roi_names = regions[:,0] # these are the names of each of 360 roi from the parcellation.\n",
    "network_names = regions[:,1] # these are the networks each roi \"belongs\" to\n",
    "networks = np.unique(regions[:,1]) # these are the unique network names \n",
    "data = loadmat('WM_fmri_subjectaverage.mat')\n",
    "condition_index = data['condition_index']\n",
    "conditions = data['conditions']\n",
    "fmri = data['fmri']\n",
    "nconditions = data['nconditions']\n",
    "nregions = data['nregions']\n",
    "nsubjects = data['nsubjects']\n",
    "subject = data['subject']\n",
    "task = data['task']\n",
    "from scipy.stats import zscore\n",
    "z = zscore(fmri)\n",
    "diff = np.mean(z[:,condition_index < 4],axis = 1) -np.mean(z[:,condition_index >3],axis = 1)\n",
    "n = 10\n",
    "ordered_index = np.argsort(np.abs(diff)) # sorts into ascending order \n",
    "topn = ordered_index[-n:] #take the last n\n",
    "for j in range(len(topn)):\n",
    "    print(roi_names[topn[j]],network_names[topn[j]], diff[topn[j]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **In this text box, write a sentence that identifies the network that shows the strongest effects, and the direction of that effect**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#taarget dection pushing a button \n",
    "# ddid ant item with a foot was there a repeat \n",
    "#  2nd manulupuation is a visual stimuli \n",
    "# for the fornal paaerial there is a strong effect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 2. Using Linear Discriminant Analysis (LDA) to classify the data by the **task** - target detection versus working memory  ('0bk' versus '2bk') combining the data across the visual stimulus types. First perform the analysis using all the brain data (all 360 ROIs).  Second, perform the analysis separately on each of the subsets of ROI belonging to each of the 12 specific labeled networks (12 classifier models). The only output required is the performance of each LDA classifier using 5-fold cross-validation.  Make a table showing the performance of the classifier for each network and for the whole brain.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a better claffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **In this text box, identify the network that shows the strongest classification performance, and compare that performance to a whole brain model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use LDA to classify all 8 experimental conditions separately for the ROIs in each of the 12 labeled networks. make a table that presents the classification performance of each network. Identify the network that has the strongest classification performance, and make a plot (using imshow) of the confusion matrix when making a model using only the ROIs in that network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **In this textbox, comment on the pattern of the confusion matrix results.  When there is an error, where does the misclassification occur?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use LDA to make a classification model of all 8 experimental conditions, combining ROIs in the network identified in Question 3, with the network identified in Question 2 as best classifying task. Compute and visualize a confusion matrix for this new two-network model. As a comparison, compute a classification model using all the ROI from the whole brain.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **In this text box, comment on the difference in performance of the two-network classification model with the whole brain classification model. Does the two-network classification model show any systematic patterns in the confusion matrix, as compared to your answer in question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('eeg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8174803ded4e24dcb3aff203efa8677f2e39ba6313b250cc46985ae8a172e02f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
