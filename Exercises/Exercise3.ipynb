{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 Quantitative Measures from ERP signals \n",
    "\n",
    "### Exercises 3 and 4 completes our discussion of extracting features from EEG experiments for building relationships with data. \n",
    "\n",
    "#### Exercise 3 is focused on extracting ERP measures (peak amplitude and latency) from ERP averages.  \n",
    "\n",
    "### We will come back to these EEG measurements when we learn about classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Perception Experiment \n",
    "\n",
    "### These data were extracted from the ERP CORE (https://osf.io/thsqg/wiki/home/).  \n",
    "\n",
    "### These are data from the experiment, **N170 Face Perception Experiment**\n",
    "\n",
    "### Some details of the experiment - \n",
    "*   The stimulus consists of four types of stimuli - Faces. Cars. Scrambled Faces, Scrambled Cars\n",
    "*   On any trial one of these stimuli are presented (with probability 0.25)\n",
    "*   On each trial, an image of a face, car, scrambled face, or scrambled car was presented in the center of the screen, and participants indicated whether a given stimulus was an “object” (face or car) or a “texture” (scrambled face or scrambled car)\n",
    "\n",
    "## THIS IS ONE OF THE STIMULUS SETS FOR THE CLASS FINAL PROJECT.  IN THE FINAL PROJECT, THE TASK WILL BE TO CHARACTERIZE THE DIFFERENCES BETWEEN THE 4 STIMULUS CLASSES AND DEVELOP A CLASSIFIER MODEL TO PREDICT WHICH STIMULUS WAS PRESENTED ON EACH TRIAL. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "from hdf5storage import loadmat, savemat \n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal  #THIS IS NEW!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are 3 data files available for your inspection, 1_N170.mat, 2_N170.mat, 3_N170.mat \n",
    "#### The 3 files have the same experiment in different participants.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('data/2_N170.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelnames = data['channelnames']\n",
    "eeg = data['eeg']\n",
    "eeg_time = data['eeg_time']\n",
    "goodtrials = data['goodtrials']\n",
    "nchannels = data['nchannels']\n",
    "ntrials = data['ntrials']\n",
    "response = data['response']\n",
    "responsetime = data['responsetime']\n",
    "samplingrate = data['samplingrate']\n",
    "stimulus = data['stimulus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README \n",
    "\n",
    "### The information about the datafiles in an experiment is normally placed in a README file. \n",
    "### For convenience I am going to place that information here instead.\n",
    "\n",
    "###  This data was obtained from the archive ERP CORE and reorganized for this class. \n",
    "###  Each file contains the data of one participant, indicated in the filename. \n",
    "###  The variables contained here are \n",
    "\n",
    "*   `ntrials` - number of trials in the experiment \n",
    "*   `nchannels` - number of EEG channels \n",
    "*   `samplingrate` - number of samples of EEG in per second\n",
    "*   `eeg` - eegdata of the experiment.  of dimensions, ntrials x nchannels x ntimepoints.  The EEG is provided in units of volts. \n",
    "*   `eeg_time` - the time relative to *stimulus onset* in each EEG observation.\n",
    "*   `channelnames` - the name of the EEG channels indicating where it is located.    \n",
    "*   `stimulus` - the stimulus presented on each good trial, 1 = face, 2 = car, 3 = scrambled face, 4 = scrambled car \n",
    "*   `response` - variable indicating the response accuracy 1 = correct, -1 = incorrect, 0 = no response,\n",
    "*   `responsetime` - time after stimulus onset when the subject provided a response. \n",
    "*   `goodtrials` - vector with value 1 if the trial had a response, 0 if no response or multiple responses.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "\n",
    "#### Compute the Event-related potential (ERP) separately for each stimulus type. \n",
    "#### Plot the data at electrodes corresponding to P3,Pz,P4 over parietal cortex, and PO7, O1,O2,PO8 over the occipital cortex.   \n",
    "#### Apply filters and extract the P300/CPP amplitude and latency (timing of the peak after stimulus presentation) at electrode Pz. \n",
    "#### Apply filters and extract the N170 amplitude and latency (timing) at one of PO7,PO8 for the face and car stimuli.  Select the electrode that has the clearest N170 for all 3 participants data.   Alternatively, you could collapse the 2 electrodes data by averaging them together.   \n",
    "#### For the scrambled face and scrambled car stimuli, use the latency of the face and car stimuli, and extract the voltage of the corresponding scrambled stimulus response.  \n",
    "####\n",
    "#### **Your notebook should run cleanly.  That is, I should be able to change which data file is being run, and it should be able to run and make all of the above plots and quantitative estimates.**  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('eeg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8174803ded4e24dcb3aff203efa8677f2e39ba6313b250cc46985ae8a172e02f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
